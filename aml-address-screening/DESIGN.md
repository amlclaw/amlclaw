# AML Address Screening — Design Document

> This document explains the architectural decisions and technical design behind the AML Address Screening skill.
> 本文档阐述 AML 地址筛查技能的架构决策和技术设计。

## 1. Overview — 概述

The AML Address Screening skill is an **LLM-native** compliance investigation tool. Unlike traditional rule engines that execute end-to-end in code, this system delegates the final evaluation and report generation to an LLM agent.

The design philosophy is a **division of labor**:
- **Python scripts** handle deterministic tasks: API calls, graph traversal, noise reduction, rule matching (things that must be mathematically precise).
- **LLM agent** handles judgment tasks: risk narrative, severity reasoning, compliance recommendations (things that require contextual understanding).

This split ensures that the LLM never hallucinates risk data (all evidence comes from pre-filtered JSON), while still leveraging its strength in generating professional audit reports.

> 设计哲学是"分工"：Python 脚本处理确定性任务（API 调用、图遍历、噪声过滤、规则匹配），LLM 处理判断性任务（风险叙述、严重性推理、合规建议）。

## 2. Architecture — 架构

### 2.1 Three-Stage Pipeline — 三阶段管道

```
Stage 1: Fetch          Stage 2: Extract           Stage 3: Evaluate
───────────────         ─────────────────          ──────────────────
fetch_graph.py    →     extract_risk_paths.py  →   LLM Agent
    │                        │                         │
    ▼                        ▼                         ▼
TrustIn KYA API         rules.json filtering       Markdown Report
    │                        │                         │
    ▼                        ▼                         ▼
raw_graph_*.json        risk_paths_*.json          reports/*.md
(full API response)     (filtered evidence)        (audit report)
```

> 三阶段：获取原始图 → 提取风险路径 → LLM 评估生成报告

### 2.2 Data Flow — 数据流

```
                    ┌─────────────┐
                    │ rules.json  │ ← Generated by aml-rule-generator
                    └──────┬──────┘
                           │
    ┌──────────────┐       │       ┌──────────────────┐
    │ TrustIn API  │       │       │ evaluation_prompt │
    └──────┬───────┘       │       └────────┬─────────┘
           │               │                │
           ▼               ▼                │
    ┌──────────────┐ ┌───────────────┐      │
    │ fetch_graph  │→│extract_risk   │      │
    │    .py       │ │  _paths.py    │      │
    └──────┬───────┘ └───────┬───────┘      │
           │                 │              │
           ▼                 ▼              ▼
    raw_graph_*.json  risk_paths_*.json → LLM Agent → reports/*.md
```

### 2.3 Orchestrator — 编排器

`run_screening.py` ties Stage 1 and Stage 2 together. It:
1. Resolves the `--scenario` flag into direction defaults and passes them to `fetch_graph.py`.
2. Calls `extract_risk_paths.py` with scenario-based rule filtering.
3. Outputs the path to the final `risk_paths_*.json` for the LLM to consume.

The LLM agent (Stage 3) is not invoked by `run_screening.py` — it reads the output file and the evaluation prompt independently.

## 3. Key Design Decisions — 关键设计决策

### 3.1 Scenario-Based Screening — 基于场景的筛查

**Problem**: Different business contexts require different rules. A deposit (inflow) check shouldn't trigger withdrawal (outflow) rules.

**Solution**: 6 predefined scenarios map to rule categories and path directions:

| Scenario | Rule Categories | Path Directions |
|---|---|---|
| `onboarding` | Deposit | inflow + outflow |
| `deposit` | Deposit | inflow + outflow |
| `withdrawal` | Withdrawal | outflow only |
| `cdd` | CDD | inflow + outflow |
| `monitoring` | Ongoing Monitoring | inflow + outflow |
| `all` | ALL | inflow + outflow |

> 6 个场景映射到规则类别和路径方向。入金检查不会触发出金规则。

**Why `deposit` fetches both directions**: Deposit rules include DEP-OUT-* rules that check outflow history ("Has this address previously sent funds to sanctioned entities?"). This is a historical risk signal, not a current withdrawal check.

### 3.2 Pollution Decay Principle — 污染衰减原则

**Problem**: A direct (1-hop) connection to a sanctioned address is far more severe than a 5-hop indirect link. Treating all hops equally causes false positives at far distances and under-reactions at close distances.

**Solution**: Rules define hop tiers via `min_hops` and `max_hops` fields:

```
Hop 1 (direct)     → Severe / Freeze    (最高风险)
Hop 2-3 (near)     → Severe / Freeze    (高风险)
Hop 4-5 (far)      → High / EDD         (需进一步尽调)
```

Each severity tier is a separate rule (e.g., `DEP-SEVERE-001` for Hop 1, `DEP-SEVERE-002` for Hop 2-3, `DEP-HIGH-001` for Hop 4-5). This replaces the old `path.node.deep` condition parameter.

> 直接连接（1 跳）比间接连接（5 跳）严重得多。规则通过 min_hops/max_hops 定义跳数分层。

### 3.3 Rule-Level Direction and Hop Filtering — 规则级方向和跳数过滤

**Problem (V1)**: Direction and hop distance were encoded as `conditions[]` entries (e.g., `path.node.deep <= 3`). This mixed contextual filtering with content matching, making rules harder to reason about.

**Solution (V2)**: Direction and hop range are **top-level rule fields**, not conditions:

```json
{
  "rule_id": "SG-DPT-DEP-SEVERE-001",
  "category": "Deposit",
  "direction": "inflow",
  "min_hops": 1,
  "max_hops": 1,
  "conditions": [
    {"parameter": "path.node.tags.primary_category", "operator": "IN", "value": ["Sanctions", "Cybercrime"]}
  ]
}
```

The `rule_applies_to_context()` function checks direction + hop range **before** evaluating conditions. This cleanly separates "when does this rule apply?" from "what does this rule match?".

> V2 将方向和跳数提升为规则的顶层字段，与条件匹配分离。

### 3.4 Positional Hop Computation — 位置化跳数计算

**Problem**: The TrustIn API's `deep` field in path nodes is unreliable — often returns all zeros regardless of actual position.

**Solution**: `compute_true_deep()` calculates hop distance from the node's position in the path array:

```python
def compute_true_deep(node_index, num_nodes, path_dir, raw_deep):
    if path_dir == -1:  # inflow: [Source(far), ..., Target(near)]
        return num_nodes - 1 - node_index
    else:               # outflow: [Target(near), ..., Dest(far)]
        return node_index
```

- **Inflow paths**: Target is the last node. Hop distance = array length - 1 - index.
- **Outflow paths**: Target is the first node. Hop distance = index.

> TrustIn API 的 deep 字段不可靠，改用数组位置计算真实跳数。

### 3.5 Evidence Path Capping — 证据路径上限

**Problem**: A single risk entity might appear in dozens of paths. Sending all paths to the LLM wastes context tokens and causes information overload.

**Solution**: Cap at **3 evidence paths per entity**. This is enough to demonstrate the pattern without overwhelming the LLM's context window.

```python
if len(entry["evidence_paths"]) < 3:
    entry["evidence_paths"].append({...})
```

> 每个风险实体最多保留 3 条证据路径，控制 LLM 上下文大小。

### 3.6 Target Self-Tag Evaluation — 目标自身标签评估

**Problem**: Some rules check the target address itself (e.g., "Is this address on a sanctions list?"), not its transaction counterparties.

**Solution**: Target self-tag evaluation is **independent of path traversal**. The system reads the target's own tags from the graph API's `data.tags` array and matches them against rules with `target.tags.*` conditions.

These rules use the naming convention:
- `DEP-SELF-*` — Deposit self-tag checks (e.g., target is sanctioned)
- `WDR-SELF-*` — Withdrawal self-tag checks

> 目标自身标签评估独立于路径遍历，直接检查目标地址是否被标记。

### 3.7 Onboarding = Deposit — 入驻等于入金

**Problem**: Should "onboarding" (KYC) and "deposit" use different rule sets?

**Decision**: No. Both use the same `Deposit` rules. Rationale:
- Risk changes over time. An address clean at onboarding might later receive tainted funds.
- Re-evaluating with the same rules at each deposit ensures consistent risk posture.
- Self-tag checks (`DEP-SELF-*`) handle the "is this address itself flagged?" question that onboarding requires.

> 入驻和入金使用相同的 Deposit 规则。风险随时间变化，每次入金都重新评估。

## 4. Rule Matching Logic — 规则匹配逻辑

The matching pipeline has two stages:

### 4.1 Context Check — `rule_applies_to_context()`

Before evaluating conditions, check if the rule applies to the current path:
1. **Direction match**: Rule's `direction` field must match the path direction (inflow/outflow). Rules without `direction` match any path.
2. **Hop range match**: Node's hop distance must fall within `[min_hops, max_hops]`. Rules without hop fields match any distance.

### 4.2 Condition Match — `rule_matches_node()`

Evaluate all node-level conditions using AND logic:
1. Each condition is checked against the node's tag.
2. Non-node-level conditions (e.g., `path.amount`) are skipped — they are evaluated by the LLM.
3. If **any** node-level condition fails → no match.
4. If **zero** node-level conditions exist → no match (the rule isn't node-evaluable).

```
For each path node:
  For each rule:
    ├── rule_applies_to_context(rule, path_dir, hop_distance)?
    │     ├── No  → skip rule
    │     └── Yes → continue
    └── rule_matches_node(rule, node_tag, hop_distance)?
          ├── No  → skip rule
          └── Yes → record match
```

> 两阶段匹配：先检查规则是否适用于当前上下文（方向+跳数），再评估条件是否匹配节点标签。

## 5. Output Format — 输出格式

### 5.1 `risk_paths_*.json` Structure

```json
{
  "target": {
    "chain": "Tron",
    "address": "T...",
    "tags": [...],
    "self_matched_rules": ["DEP-SELF-SEVERE-001"]
  },
  "scenario": "deposit",
  "summary": {
    "scenario": "deposit",
    "categories_applied": ["Deposit"],
    "total_paths_analyzed": 50,
    "paths_direction_filtered": 20,
    "unique_risk_entities": 8,
    "rules_loaded": 10,
    "rules_total_available": 19,
    "rules_triggered": ["DEP-SEVERE-001", "DEP-HIGH-001"],
    "highest_severity": "Severe"
  },
  "risk_entities": [
    {
      "address": "T...",
      "min_deep": 1,
      "tag": {...},
      "matched_rules": ["DEP-SEVERE-001"],
      "evidence_paths": [
        {
          "path_index": 5,
          "deep": 1,
          "flow": "[Source (Sanctions)] --(1000 USD)--> [Target]"
        }
      ],
      "occurrences": 3
    }
  ]
}
```

### 5.2 LLM Report Template

The LLM reads `evaluation_prompt.md` which defines the Markdown report structure:
- Executive Summary with Risk Score (0-100)
- Target Identity section
- Triggered Rules table
- Evidence Chain details with fund flow diagrams
- Recommended Actions

> LLM 根据 evaluation_prompt.md 模板生成最终的审计报告。
